{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94663fec-03ce-4605-89c9-da9e3149cbaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>序号</th>\n",
       "      <th>用户名</th>\n",
       "      <th>等级</th>\n",
       "      <th>性别</th>\n",
       "      <th>评论</th>\n",
       "      <th>点赞数</th>\n",
       "      <th>评论时间</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>煜轩殿下</td>\n",
       "      <td>6</td>\n",
       "      <td>男</td>\n",
       "      <td>先做个大胆的假设，这个视频十年后还会被顶上来[小电视_赞]</td>\n",
       "      <td>112946</td>\n",
       "      <td>2019-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Yamiヤミ闇</td>\n",
       "      <td>6</td>\n",
       "      <td>保密</td>\n",
       "      <td>这首歌毁了多少人的四级听力</td>\n",
       "      <td>136285</td>\n",
       "      <td>2018-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>嗑糖少女OOO</td>\n",
       "      <td>6</td>\n",
       "      <td>保密</td>\n",
       "      <td>以前谁上春晚谁火，现在谁火谁上春晚</td>\n",
       "      <td>364547</td>\n",
       "      <td>2018-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>盒子想吃肉</td>\n",
       "      <td>6</td>\n",
       "      <td>女</td>\n",
       "      <td>其实笑完真的心里有点酸酸的，以前家族人多，除夕的时候，年夜饭吃的早，收拾晚了刚好春晚开始，那...</td>\n",
       "      <td>329371</td>\n",
       "      <td>2018-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>花痴簡花痴</td>\n",
       "      <td>5</td>\n",
       "      <td>男</td>\n",
       "      <td>今天去洗澡，洗着洗着就唱起了改革吹风春满地。。。澡堂子一群人看着我，更可怕的是有人还来了句中...</td>\n",
       "      <td>61373</td>\n",
       "      <td>2018-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   序号      用户名  等级  性别                                                 评论  \\\n",
       "0   1     煜轩殿下   6   男                      先做个大胆的假设，这个视频十年后还会被顶上来[小电视_赞]   \n",
       "1   2  Yamiヤミ闇   6  保密                                      这首歌毁了多少人的四级听力   \n",
       "2   3  嗑糖少女OOO   6  保密                                  以前谁上春晚谁火，现在谁火谁上春晚   \n",
       "3   4    盒子想吃肉   6   女  其实笑完真的心里有点酸酸的，以前家族人多，除夕的时候，年夜饭吃的早，收拾晚了刚好春晚开始，那...   \n",
       "4   5    花痴簡花痴   5   男  今天去洗澡，洗着洗着就唱起了改革吹风春满地。。。澡堂子一群人看着我，更可怕的是有人还来了句中...   \n",
       "\n",
       "      点赞数     评论时间  \n",
       "0  112946  2019-01  \n",
       "1  136285  2018-12  \n",
       "2  364547  2018-02  \n",
       "3  329371  2018-12  \n",
       "4   61373  2018-12  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "data0 = pd.read_excel(r\"赵本山念诗之王鬼畜评论.xlsx\")\n",
    "data0.head()\n",
    "\n",
    "#修改评论时间的格式\n",
    "\n",
    "timenot=data0[\"评论时间\"]\n",
    "timenot = timenot.map(lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\"))\n",
    "timeyes=timenot.dt.strftime(\"%Y-%m\")\n",
    "data0[\"评论时间\"]=timeyes\n",
    "data1=data0\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1535e561-0904-429d-be2b-cb36072fe2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = data1.sort_values(by=\"评论时间\",ascending=True)  # by指定按哪列排序,scending表示是否升序\n",
    "data2018 = da[(da[\"评论时间\"] >= \"2018-02\") & (da[\"评论时间\"] <\"2019-02\")]\n",
    "data2019 = da[(da[\"评论时间\"] >= \"2019-02\") & (da[\"评论时间\"] <\"2020-02\")]\n",
    "data2020 = da[(da[\"评论时间\"] >= \"2020-02\") & (da[\"评论时间\"] <\"2021-02\")]\n",
    "data2021 = da[(da[\"评论时间\"] >= \"2021-02\") & (da[\"评论时间\"] <\"2022-03\")]\n",
    "data20182019 = da[(da[\"评论时间\"] >= \"2018-02\") & (da[\"评论时间\"] <\"2020-02\")]\n",
    "data20202021 = da[(da[\"评论时间\"] >= \"2020-02\") & (da[\"评论时间\"] <\"2022-03\")]\n",
    "datahigh1 = da[(da[\"评论时间\"] >= \"2019-01\") & (da[\"评论时间\"] <\"2019-03\")] \n",
    "datahigh3 = da[(da[\"评论时间\"] >= \"2021-01\") & (da[\"评论时间\"] <\"2021-03\")]\n",
    "datahigh2 = da[(da[\"评论时间\"] >= \"2020-02\") & (da[\"评论时间\"] <\"2020-03\")]\n",
    "datahigh4 = da[(da[\"评论时间\"] >= \"2021-07\") & (da[\"评论时间\"] <\"2021-08\")]\n",
    "datahigh5 = da[(da[\"评论时间\"] >= \"2022-01\") & (da[\"评论时间\"] <\"2022-03\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5354e72f-aca3-464a-aa83-a7eeff373b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\12297\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.431 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总词汇量：69691\n",
      "不重复词汇量：7103\n",
      "[('版', 6627), ('吹', 759), ('满地', 755), ('春风', 636), ('改革', 530), ('世界', 445), ('争气', 351), ('火辣辣', 332), ('老师', 293), ('ﾟ', 234), ('抖音', 221), ('鬼畜', 208), ('填词', 208), ('原版', 205), ('听', 199), ('av19390801', 198), ('德隆', 197), ('影版', 197), ('柯南版', 187), ('猫和老鼠', 186), ('中国', 183), ('日语', 183), ('计算器', 173), ('家', 172), ('唢呐', 172), ('二胡', 171), ('av37883690', 171), ('春晚', 170), ('av37550148', 169), ('古筝', 169), ('av37814739', 169), ('笛子', 169), ('av38275710', 169), ('葫芦丝', 169), ('av38622329', 169), ('av38787790', 168), ('埃罗芒', 167), ('小提琴', 165), ('龙', 164), ('av39312110', 164), ('av39921232', 163), ('名字', 162), ('面筋', 162), ('从零开始', 162), ('异', 162), ('狐', 161), ('av37736499', 161), ('魔禁', 161), ('超炮', 161), ('av38491246', 161), ('小林', 161), ('女仆', 161), ('刀剑', 159), ('神域', 159), ('av40368922', 159), ('av38583383', 159), ('刺客', 159), ('六七', 159), ('家庭', 158), ('av38769543', 158), ('伍', 158), ('av39707377', 158), ('av39924036', 158), ('一人之下', 158), ('约会', 157), ('作战', 157), ('av39769312', 157), ('av40134217', 157), ('猫', 156), ('教师版', 156), ('疯狂', 155), ('ا', 154), ('C', 153), ('av40429335pop', 153), ('av38264323', 153), ('哈利波', 153), ('av38116738', 153), ('大哥大', 153), ('av40423488', 153), ('av39504119', 152), ('特版', 152), ('av40009200', 152), ('红小豆', 152), ('av39751761', 152), ('阴阳师', 152), ('憨豆', 152), ('av40371785', 151), ('伴娘', 150), ('av40359141', 149), ('东方', 149), ('打针', 148), ('念诗', 148), ('av39228264', 148), ('av40268693', 148), ('美利坚', 148), ('av40210626', 146), ('av37819284', 146), ('吃药', 145), ('b', 145), ('俄罗斯', 145)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\12297\\\\python学习\\\\python数据分析\\\\word2018.html'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import jieba\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from pyecharts.charts import WordCloud\n",
    "from pyecharts.globals import SymbolType\n",
    "from pyecharts import options as opts\n",
    "from pyecharts.globals import ThemeType, CurrentConfig\n",
    "\n",
    "comment20180=data2018[\"评论\"]\n",
    "\n",
    "#清除特殊符号\n",
    "pattern = r\"[!\\\"#$%&'()*+,-./:;<=>?@[\\\\\\]^_^{|}~—！，。？、￥…（）：【】《》‘’“”\\s]+\"\n",
    "re_obj = re.compile(pattern)\n",
    "def clear(text):\n",
    "    return re_obj.sub(\"\",text)\n",
    "comment20181= comment20180.apply(clear)\n",
    "\n",
    "# 生成分词\n",
    "comment20182 = comment20181.apply(lambda x : list(jieba.cut(x)))\n",
    "\n",
    "#停用词处理\n",
    "def get_stopword():\n",
    "    s = set()\n",
    "    with open(r\"呆萌的停用词表.txt\",encoding = 'UTF-8') as f:\n",
    "        for line in f:\n",
    "            s.add(line.strip())\n",
    "    return s\n",
    "\n",
    "def remove_stopword(words):\n",
    "    return [word for word in words if word not in stopword]\n",
    "\n",
    "stopword = get_stopword()\n",
    "comment2018 = comment20182.apply(remove_stopword)\n",
    "\n",
    "#词频统计\n",
    "li_2d = comment2018.tolist()\n",
    "#将二维列表转换为一维\n",
    "li_1d = list(chain.from_iterable(li_2d))\n",
    "print(f'总词汇量：{len(li_1d)}')\n",
    "c = Counter(li_1d)\n",
    "print(f'不重复词汇量：{len(c)}')\n",
    "common = c.most_common(100)\n",
    "print(common)\n",
    "\n",
    "#生成词云图\n",
    "word2018 = WordCloud(init_opts=opts.InitOpts(width='1350px', height='750px', theme=ThemeType.MACARONS))\n",
    "word2018.add('common', data_pair=common,\n",
    "          word_size_range=[15, 108], textstyle_opts=opts.TextStyleOpts(font_family='cursive'),\n",
    "          shape=SymbolType.DIAMOND)\n",
    "word2018.set_global_opts(title_opts=opts.TitleOpts('word2018'),\n",
    "                         toolbox_opts=opts.ToolboxOpts(is_show=True, orient='vertical'),\n",
    "                         tooltip_opts=opts.TooltipOpts(is_show=True, background_color='red', border_color='yellow'))\n",
    "word2018.render(\"word2018.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c383f859-0812-4032-9f83-1f6f11291cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总词汇量：37661\n",
      "不重复词汇量：4622\n",
      "[('版', 3904), ('满地', 304), ('吹', 301), ('春风', 261), ('改革', 223), ('世界', 216), ('哥版', 198), ('争气', 153), ('老师', 151), ('火辣辣', 138), ('填词', 133), ('日语', 118), ('请', 115), ('火', 115), ('妖', 115), ('av19390801', 114), ('佩奇', 113), ('名字', 112), ('原版', 110), ('猫和老鼠', 110), ('念诗', 108), ('播放', 108), ('成龙', 107), ('av38754365', 105), ('章鱼', 105), ('av39391636', 105), ('之王', 104), ('古筝', 104), ('av38275710', 104), ('笛子', 104), ('面筋', 104), ('av40031051', 104), ('av38787790', 103), ('计算器', 103), ('av37814739', 103), ('av37883690', 103), ('唢呐', 103), ('av38622329', 103), ('葫芦丝', 103), ('av39921232', 103), ('小提琴', 103), ('刀剑', 103), ('神域', 103), ('av38829614', 102), ('av40210626', 102), ('二胡', 101), ('av38143437', 101), ('av39146467', 101), ('熊出没', 101), ('av40423488', 100), ('喜羊', 99), ('羊版', 99), ('av38942954', 97), ('琵琶', 97), ('狐', 97), ('龙', 97), ('av40359141', 96), ('埃罗芒', 96), ('家', 96), ('从零开始', 95), ('红小豆', 95), ('av37819284', 95), ('av39312110', 94), ('异', 94), ('一人之下', 94), ('东方', 94), ('av38790762', 94), ('约会', 94), ('除夕', 93), ('柯南版', 93), ('av38583383', 93), ('刺客', 93), ('伍', 93), ('六七', 93), ('av37736499', 93), ('魔禁', 93), ('超炮', 93), ('av39707377', 93), ('av38491246', 93), ('小林', 93), ('女仆', 93), ('av39924036', 93), ('av39504119', 93), ('av39769312', 93), ('av40134217', 93), ('av40429335pop', 93), ('av38264323', 93), ('哈利波', 93), ('av38116738', 93), ('大哥大', 93), ('av37717567', 93), ('av40009200', 93), ('av39751761', 93), ('阴阳师', 93), ('憨豆', 93), ('作战', 93), ('av40484502', 93), ('血小板', 93), ('av39318292', 93), ('王者', 93)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\12297\\\\python学习\\\\python数据分析\\\\word2019.html'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment20190=data2019[\"评论\"]\n",
    "\n",
    "#清除特殊符号\n",
    "pattern = r\"[!\\\"#$%&'()*+,-./:;<=>?@[\\\\\\]^_^{|}~—！，。？、￥…（）：【】《》‘’“”\\s]+\"\n",
    "re_obj = re.compile(pattern)\n",
    "def clear(text):\n",
    "    return re_obj.sub(\"\",text)\n",
    "comment20191= comment20190.apply(clear)\n",
    "\n",
    "# 生成分词\n",
    "comment20192 = comment20191.apply(lambda x : list(jieba.cut(x)))\n",
    "\n",
    "#停用词处理\n",
    "\n",
    "def get_stopword():\n",
    "    s = set()\n",
    "    with open(r\"呆萌的停用词表.txt\",encoding = 'UTF-8') as f:\n",
    "        for line in f:\n",
    "            s.add(line.strip())\n",
    "    return s\n",
    "\n",
    "def remove_stopword(words):\n",
    "    return [word for word in words if word not in stopword]\n",
    "\n",
    "stopword = get_stopword()\n",
    "comment2019 = comment20192.apply(remove_stopword)\n",
    "\n",
    "#词频统计\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "li_2d = comment2019.tolist()\n",
    "#将二维列表转换为一维\n",
    "li_1d = list(chain.from_iterable(li_2d))\n",
    "print(f'总词汇量：{len(li_1d)}')\n",
    "c = Counter(li_1d)\n",
    "print(f'不重复词汇量：{len(c)}')\n",
    "common = c.most_common(100)\n",
    "print(common)\\\n",
    "\n",
    "#生成词云图\n",
    "word2019 = WordCloud(init_opts=opts.InitOpts(width='1350px', height='750px', theme=ThemeType.MACARONS))\n",
    "word2019.add('common', data_pair=common,\n",
    "          word_size_range=[15, 108], textstyle_opts=opts.TextStyleOpts(font_family='cursive'),\n",
    "          shape=SymbolType.DIAMOND)\n",
    "word2019.set_global_opts(title_opts=opts.TitleOpts('word2018'),\n",
    "                         toolbox_opts=opts.ToolboxOpts(is_show=True, orient='vertical'),\n",
    "                         tooltip_opts=opts.TooltipOpts(is_show=True, background_color='red', border_color='yellow'))\n",
    "word2019.render(\"word2019.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d736af50-7033-480d-9fcf-0860b62df3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总词汇量：44499\n",
      "不重复词汇量：8257\n",
      "[('考古', 824), ('播放', 622), ('弹幕', 576), ('打卡', 496), ('宝岛', 409), ('之宝', 366), ('万', 352), ('吹', 342), ('鬼畜', 338), ('加油', 331), ('镇站', 315), ('春风', 307), ('手机', 291), ('笑', 276), ('刷', 258), ('满地', 254), ('春晚', 249), ('时代', 243), ('增加', 224), ('️', 221), ('震动', 221), ('两年', 217), ('改革', 210), ('哭', 205), ('知识', 203), ('武汉', 197), ('B', 193), ('念诗', 188), ('call', 187), ('真的', 186), ('赵本山', 181), ('之王', 173), ('一遍', 164), ('影流', 162), ('前来', 158), ('时间', 157), ('b', 152), ('世界', 145), ('听', 140), ('妙', 140), ('爱', 132), ('大哭', 132), ('回来', 129), ('小品', 126), ('中国', 126), ('记得', 126), ('亿', 125), ('经典', 125), ('为啥', 120), ('助攻', 119), ('之主', 117), ('感觉', 115), ('冲冲', 111), ('争气', 111), ('微笑', 110), ('风景', 108), ('喜极而泣', 102), ('主', 99), ('版', 98), ('呲', 97), ('亿遍', 97), ('牙', 96), ('tv', 94), ('滑稽', 92), ('号', 92), ('有人', 91), ('希望', 90), ('蛆', 89), ('音娘', 89), ('十万', 87), ('请', 86), ('风云', 85), ('纵观', 84), ('OK', 84), ('本山', 82), ('吃', 81), ('第一', 81), ('变', 79), ('歪嘴', 79), ('DNA', 78), ('粉丝', 77), ('C', 77), ('钉', 75), ('里', 75), ('机智', 75), ('发现', 74), ('喜欢', 74), ('过年', 73), ('发', 72), ('超过', 72), ('作品', 72), ('完', 71), ('区', 70), ('圣诞', 70), ('国外', 69), ('再来', 68), ('牛', 66), ('投币', 66), ('火', 65), ('更好', 65)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\12297\\\\python学习\\\\python数据分析\\\\word2020.html'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import jieba\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "comment20200=data2020[\"评论\"]\n",
    "\n",
    "#清除特殊符号\n",
    "pattern = r\"[!\\\"#$%&'()*+,-./:;<=>?@[\\\\\\]^_^{|}~—！，。？、￥…（）：【】《》‘’“”\\s]+\"\n",
    "re_obj = re.compile(pattern)\n",
    "def clear(text):\n",
    "    return re_obj.sub(\"\",text)\n",
    "comment20201= comment20200.apply(clear)\n",
    "\n",
    "# 生成分词\n",
    "comment20202 = comment20201.apply(lambda x : list(jieba.cut(x)))\n",
    "\n",
    "#停用词处理\n",
    "\n",
    "def get_stopword():\n",
    "    s = set()\n",
    "    with open(r\"呆萌的停用词表.txt\",encoding = 'UTF-8') as f:\n",
    "        for line in f:\n",
    "            s.add(line.strip())\n",
    "    return s\n",
    "\n",
    "def remove_stopword(words):\n",
    "    return [word for word in words if word not in stopword]\n",
    "\n",
    "stopword = get_stopword()\n",
    "comment2020 = comment20202.apply(remove_stopword)\n",
    "\n",
    "#词频统计\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "li_2d = comment2020.tolist()\n",
    "#将二维列表转换为一维\n",
    "li_1d = list(chain.from_iterable(li_2d))\n",
    "print(f'总词汇量：{len(li_1d)}')\n",
    "c = Counter(li_1d)\n",
    "print(f'不重复词汇量：{len(c)}')\n",
    "common = c.most_common(100)\n",
    "print(common)\n",
    "\n",
    "#生成词云图\n",
    "word2020 = WordCloud(init_opts=opts.InitOpts(width='1350px', height='750px', theme=ThemeType.MACARONS))\n",
    "word2020.add('common', data_pair=common,\n",
    "          word_size_range=[15, 108], textstyle_opts=opts.TextStyleOpts(font_family='cursive'),\n",
    "          shape=SymbolType.DIAMOND)\n",
    "word2020.set_global_opts(title_opts=opts.TitleOpts('word2018'),\n",
    "                         toolbox_opts=opts.ToolboxOpts(is_show=True, orient='vertical'),\n",
    "                         tooltip_opts=opts.TooltipOpts(is_show=True, background_color='red', border_color='yellow'))\n",
    "word2020.render(\"word2020.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "457a7a4a-8a0b-4407-9b6e-9538a8fab6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总词汇量：31326\n",
      "不重复词汇量：5996\n",
      "[('一亿', 721), ('打卡', 608), ('新年快乐', 514), ('考古', 512), ('助攻', 504), ('一遍', 502), ('播放', 397), ('吹', 377), ('亿', 331), ('弹幕', 302), ('亿遍', 285), ('春风', 280), ('脱单', 271), ('再来', 262), ('笑', 258), ('满地', 245), ('妙', 233), ('改革', 231), ('ω', 214), ('春晚', 208), ('哭', 200), ('call', 196), ('鬼畜', 188), ('万', 175), ('入站', 171), ('经典', 168), ('必刷', 168), ('加油', 165), ('小品', 144), ('三年', 142), ('之宝', 132), ('时间', 127), ('过年', 124), ('大哭', 121), ('回来', 120), ('镇站', 119), ('增加', 117), ('知识', 115), ('･', 113), ('刷', 112), ('赵本山', 107), ('辣', 105), ('真的', 105), ('前来', 101), ('微笑', 96), ('本山', 96), ('冲冲', 92), ('眼睛', 91), ('福到', 88), ('助力', 88), ('藏狐', 87), ('宝岛', 86), ('有人', 83), ('影流', 80), ('重温', 79), ('听', 78), ('感觉', 77), ('四年', 77), ('OK', 75), ('记得', 75), ('怀念', 74), ('虎年', 74), ('️', 73), ('大叔', 71), ('快乐', 70), ('b', 69), ('手机', 68), ('tv', 67), ('吃', 65), ('之主', 63), ('震动', 63), ('滑稽', 62), ('爆热词', 62), ('爱', 61), ('时代', 61), ('B', 59), ('爆', 59), ('牛', 57), ('永远', 57), ('河南', 57), ('上头', 56), ('完', 56), ('好家伙', 55), ('回顾', 54), ('DNA', 53), ('星星', 52), ('希望', 52), ('眼', 51), ('冰墩', 51), ('每日', 50), ('老师', 50), ('真快', 50), ('隔壁', 49), ('る', 49), ('墩', 49), ('百亿', 48), ('嗑瓜子', 47), ('为啥', 47), ('豫', 47), ('脸红', 47)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\12297\\\\python学习\\\\python数据分析\\\\word2021.html'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import jieba\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "comment20210=data2021[\"评论\"]\n",
    "\n",
    "#清除特殊符号\n",
    "pattern = r\"[!\\\"#$%&'()*+,-./:;<=>?@[\\\\\\]^_^{|}~—！，。？、￥…（）：【】《》‘’“”\\s]+\"\n",
    "re_obj = re.compile(pattern)\n",
    "def clear(text):\n",
    "    return re_obj.sub(\"\",text)\n",
    "comment20211= comment20210.apply(clear)\n",
    "\n",
    "# 生成分词\n",
    "comment20212 = comment20211.apply(lambda x : list(jieba.cut(x)))\n",
    "\n",
    "#停用词处理\n",
    "\n",
    "def get_stopword():\n",
    "    s = set()\n",
    "    with open(r\"呆萌的停用词表.txt\",encoding = 'UTF-8') as f:\n",
    "        for line in f:\n",
    "            s.add(line.strip())\n",
    "    return s\n",
    "\n",
    "def remove_stopword(words):\n",
    "    return [word for word in words if word not in stopword]\n",
    "\n",
    "stopword = get_stopword()\n",
    "comment2021 = comment20212.apply(remove_stopword)\n",
    "\n",
    "#词频统计\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "li_2d = comment2021.tolist()\n",
    "#将二维列表转换为一维\n",
    "li_1d = list(chain.from_iterable(li_2d))\n",
    "print(f'总词汇量：{len(li_1d)}')\n",
    "c = Counter(li_1d)\n",
    "print(f'不重复词汇量：{len(c)}')\n",
    "common = c.most_common(100)\n",
    "print(common)\n",
    "\n",
    "#生成词云图\n",
    "word2021 = WordCloud(init_opts=opts.InitOpts(width='1350px', height='750px', theme=ThemeType.MACARONS))\n",
    "word2021.add('common', data_pair=common,\n",
    "          word_size_range=[15, 108], textstyle_opts=opts.TextStyleOpts(font_family='cursive'),\n",
    "          shape=SymbolType.DIAMOND)\n",
    "word2021.set_global_opts(title_opts=opts.TitleOpts('word2018'),\n",
    "                         toolbox_opts=opts.ToolboxOpts(is_show=True, orient='vertical'),\n",
    "                         tooltip_opts=opts.TooltipOpts(is_show=True, background_color='red', border_color='yellow'))\n",
    "word2021.render(\"word2021.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66259147-d196-4fe6-8f21-780bacdc6f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总词汇量：106730\n",
      "不重复词汇量：9498\n",
      "[('版', 10531), ('吹', 1060), ('满地', 1059), ('春风', 897), ('改革', 753), ('世界', 661), ('争气', 504), ('火辣辣', 470), ('老师', 444), ('填词', 341), ('原版', 315), ('av19390801', 312), ('日语', 301), ('鬼畜', 296), ('猫和老鼠', 296), ('听', 288), ('影版', 288), ('柯南版', 280), ('计算器', 276), ('唢呐', 275), ('德隆', 274), ('名字', 274), ('av37883690', 274), ('ﾟ', 273), ('古筝', 273), ('笛子', 273), ('av38275710', 273), ('二胡', 272), ('av37814739', 272), ('葫芦丝', 272), ('av38622329', 272), ('av38787790', 271), ('家', 268), ('小提琴', 268), ('面筋', 266), ('av39921232', 266), ('埃罗芒', 263), ('刀剑', 262), ('神域', 262), ('抖音', 261), ('龙', 261), ('av37550148', 260), ('春晚', 259), ('佩奇', 258), ('狐', 258), ('av39312110', 258), ('从零开始', 257), ('念诗', 256), ('异', 256), ('av37736499', 254), ('魔禁', 254), ('超炮', 254), ('av38491246', 254), ('小林', 254), ('女仆', 254), ('av40423488', 253), ('播放', 252), ('av38583383', 252), ('刺客', 252), ('六七', 252), ('一人之下', 252), ('约会', 251), ('伍', 251), ('av39707377', 251), ('av39924036', 251), ('中国', 250), ('作战', 250), ('av39769312', 250), ('av40134217', 250), ('av39391636', 249), ('成龙', 249), ('av40368922', 249), ('家庭', 248), ('av40031051', 248), ('av38754365', 248), ('章鱼', 248), ('av40210626', 248), ('红小豆', 247), ('教师版', 246), ('av40429335pop', 246), ('av38264323', 246), ('哈利波', 246), ('av38116738', 246), ('大哥大', 246), ('av40359141', 245), ('av39504119', 245), ('av40009200', 245), ('av39751761', 245), ('阴阳师', 245), ('憨豆', 245), ('av39146467', 244), ('熊出没', 244), ('之王', 243), ('av38829614', 243), ('东方', 243), ('特版', 242), ('琵琶', 241), ('av38143437', 241), ('av40371785', 241), ('av37819284', 241)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\12297\\\\python学习\\\\python数据分析\\\\word20182019.html'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment201820190=data20182019[\"评论\"]\n",
    "\n",
    "#清除特殊符号\n",
    "pattern = r\"[!\\\"#$%&'()*+,-./:;<=>?@[\\\\\\]^_^{|}~—！，。？、￥…（）：【】《》‘’“”\\s]+\"\n",
    "re_obj = re.compile(pattern)\n",
    "def clear(text):\n",
    "    return re_obj.sub(\"\",text)\n",
    "comment201820191= comment201820190.apply(clear)\n",
    "\n",
    "# 生成分词\n",
    "comment201820192 = comment201820191.apply(lambda x : list(jieba.cut(x)))\n",
    "\n",
    "#停用词处理\n",
    "\n",
    "def get_stopword():\n",
    "    s = set()\n",
    "    with open(r\"呆萌的停用词表.txt\",encoding = 'UTF-8') as f:\n",
    "        for line in f:\n",
    "            s.add(line.strip())\n",
    "    return s\n",
    "\n",
    "def remove_stopword(words):\n",
    "    return [word for word in words if word not in stopword]\n",
    "\n",
    "stopword = get_stopword()\n",
    "comment20182019 = comment201820192.apply(remove_stopword)\n",
    "\n",
    "#词频统计\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "li_2d = comment20182019.tolist()\n",
    "#将二维列表转换为一维\n",
    "li_1d = list(chain.from_iterable(li_2d))\n",
    "print(f'总词汇量：{len(li_1d)}')\n",
    "c = Counter(li_1d)\n",
    "print(f'不重复词汇量：{len(c)}')\n",
    "common = c.most_common(100)\n",
    "print(common)\n",
    "\n",
    "#生成词云图\n",
    "word20182019 = WordCloud(init_opts=opts.InitOpts(width='1350px', height='750px', theme=ThemeType.MACARONS))\n",
    "word20182019.add('common', data_pair=common,\n",
    "          word_size_range=[15, 108], textstyle_opts=opts.TextStyleOpts(font_family='cursive'),\n",
    "          shape=SymbolType.DIAMOND)\n",
    "word20182019.set_global_opts(title_opts=opts.TitleOpts('word2018'),\n",
    "                         toolbox_opts=opts.ToolboxOpts(is_show=True, orient='vertical'),\n",
    "                         tooltip_opts=opts.TooltipOpts(is_show=True, background_color='red', border_color='yellow'))\n",
    "word20182019.render(\"word20182019.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60878b6d-62a8-4fc3-aad1-333d9f0d3da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总词汇量：75363\n",
      "不重复词汇量：11566\n",
      "[('考古', 1336), ('打卡', 1104), ('播放', 1019), ('弹幕', 878), ('一亿', 786), ('吹', 719), ('一遍', 666), ('助攻', 623), ('春风', 587), ('笑', 534), ('万', 527), ('鬼畜', 526), ('新年快乐', 526), ('满地', 499), ('之宝', 498), ('加油', 496), ('宝岛', 495), ('春晚', 457), ('亿', 456), ('改革', 441), ('镇站', 434), ('哭', 405), ('call', 383), ('亿遍', 382), ('妙', 373), ('刷', 370), ('手机', 359), ('增加', 341), ('再来', 330), ('知识', 318), ('时代', 304), ('️', 294), ('经典', 293), ('真的', 291), ('赵本山', 288), ('时间', 284), ('震动', 284), ('脱单', 271), ('小品', 270), ('前来', 259), ('大哭', 253), ('回来', 249), ('ω', 248), ('影流', 242), ('两年', 232), ('b', 221), ('念诗', 218), ('听', 218), ('之王', 208), ('微笑', 206), ('冲冲', 203), ('记得', 201), ('武汉', 197), ('过年', 197), ('爱', 193), ('三年', 193), ('感觉', 192), ('入站', 191), ('世界', 187), ('必刷', 187), ('之主', 180), ('本山', 178), ('有人', 174), ('为啥', 167), ('tv', 161), ('OK', 159), ('滑稽', 154), ('中国', 153), ('吃', 146), ('争气', 144), ('希望', 142), ('喜极而泣', 137), ('风景', 134), ('DNA', 131), ('辣', 129), ('号', 128), ('完', 127), ('呲', 127), ('怀念', 126), ('大叔', 126), ('主', 125), ('牙', 125), ('･', 125), ('牛', 123), ('里', 120), ('永远', 119), ('助力', 119), ('重温', 119), ('喜欢', 115), ('第一', 112), ('眼睛', 110), ('发现', 109), ('风云', 108), ('发', 107), ('上头', 107), ('快乐', 107), ('纵观', 106), ('作品', 106), ('眼', 105), ('区', 105), ('变', 104), ('爆', 103), ('版', 103)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\12297\\\\python学习\\\\python数据分析\\\\word20202021.html'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment202020210=data20202021[\"评论\"]\n",
    "\n",
    "#清除特殊符号\n",
    "pattern = r\"[!\\\"#$%&'()*+,-./:;<=>?@[\\\\\\]^_^{|}~—！，。？、￥…（）：【】《》‘’“”\\s]+\"\n",
    "re_obj = re.compile(pattern)\n",
    "def clear(text):\n",
    "    return re_obj.sub(\"\",text)\n",
    "comment202020211= comment202020210.apply(clear)\n",
    "\n",
    "# 生成分词\n",
    "comment202020212 = comment202020211.apply(lambda x : list(jieba.cut(x)))\n",
    "\n",
    "#停用词处理\n",
    "\n",
    "def get_stopword():\n",
    "    s = set()\n",
    "    with open(r\"呆萌的停用词表.txt\",encoding = 'UTF-8') as f:\n",
    "        for line in f:\n",
    "            s.add(line.strip())\n",
    "    return s\n",
    "\n",
    "def remove_stopword(words):\n",
    "    return [word for word in words if word not in stopword]\n",
    "\n",
    "stopword = get_stopword()\n",
    "comment20202021 = comment202020212.apply(remove_stopword)\n",
    "\n",
    "#词频统计\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "li_2d = comment20202021.tolist()\n",
    "#将二维列表转换为一维\n",
    "li_1d = list(chain.from_iterable(li_2d))\n",
    "print(f'总词汇量：{len(li_1d)}')\n",
    "c = Counter(li_1d)\n",
    "print(f'不重复词汇量：{len(c)}')\n",
    "common = c.most_common(103)\n",
    "print(common)\n",
    "\n",
    "#生成词云图\n",
    "word20202021 = WordCloud(init_opts=opts.InitOpts(width='1350px', height='750px', theme=ThemeType.MACARONS))\n",
    "word20202021.add('common', data_pair=common,\n",
    "          word_size_range=[15, 108], textstyle_opts=opts.TextStyleOpts(font_family='cursive'),\n",
    "          shape=SymbolType.DIAMOND)\n",
    "word20202021.set_global_opts(title_opts=opts.TitleOpts('word2018'),\n",
    "                         toolbox_opts=opts.ToolboxOpts(is_show=True, orient='vertical'),\n",
    "                         tooltip_opts=opts.TooltipOpts(is_show=True, background_color='red', border_color='yellow'))\n",
    "word20202021.render(\"word20202021.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c1ba8b-a58b-4cef-9f80-e450d2888e4e",
   "metadata": {},
   "source": [
    "## 是否要爬取春节时期的？区分节庆期间和平日的差异？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e5f6205-97fd-46f5-9dfb-617c4c9f1368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总词汇量：83017\n",
      "不重复词汇量：6575\n",
      "[('版', 9795), ('满地', 745), ('吹', 744), ('春风', 650), ('改革', 552), ('世界', 481), ('哥版', 473), ('老师', 352), ('妖', 346), ('火', 326), ('填词', 321), ('争气', 291), ('av19390801', 286), ('火辣辣', 285), ('原版', 282), ('猫和老鼠', 276), ('影版', 276), ('日语', 275), ('柯南版', 268), ('计算器', 262), ('av37883690', 259), ('唢呐', 259), ('二胡', 258), ('av38787790', 257), ('古筝', 257), ('av38275710', 257), ('笛子', 257), ('av38622329', 257), ('葫芦丝', 257), ('av37814739', 256), ('小提琴', 254), ('av39921232', 252), ('面筋', 249), ('埃罗芒', 248), ('家', 247), ('av37550148', 246), ('刀剑', 246), ('神域', 246), ('av39312110', 245), ('龙', 245), ('佩奇', 243), ('狐', 243), ('从零开始', 243), ('异', 243), ('名字', 243), ('av37736499', 239), ('魔禁', 239), ('超炮', 239), ('av38491246', 239), ('小林', 239), ('女仆', 239), ('ﾟ', 239), ('av38583383', 237), ('刺客', 237), ('六七', 237), ('伍', 236), ('av39707377', 236), ('av39924036', 236), ('一人之下', 236), ('av39769312', 235), ('av40134217', 235), ('家庭', 235), ('av40423488', 235), ('av40031051', 234), ('av39391636', 234), ('成龙', 234), ('av40368922', 234), ('教师版', 234), ('av38754365', 233), ('章鱼', 233), ('av40210626', 233), ('约会', 233), ('红小豆', 232), ('作战', 232), ('av40429335pop', 231), ('av38264323', 231), ('哈利波', 231), ('av38116738', 231), ('大哥大', 231), ('av39146467', 230), ('熊出没', 230), ('av40359141', 230), ('av39504119', 230), ('特版', 230), ('av40009200', 230), ('av39751761', 230), ('阴阳师', 230), ('憨豆', 230), ('av40371785', 229), ('av38829614', 228), ('东方', 228), ('av38143437', 227), ('喜羊', 227), ('羊版', 227), ('av40268693', 227), ('av37819284', 226), ('av38942954', 225), ('琵琶', 225), ('av39228264', 225), ('美利坚', 225)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\12297\\\\python学习\\\\python数据分析\\\\wordhigh1.html'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commenthigh10=datahigh1[\"评论\"]\n",
    "\n",
    "#清除特殊符号\n",
    "pattern = r\"[!\\\"#$%&'()*+,-./:;<=>?@[\\\\\\]^_^{|}~—！，。？、￥…（）：【】《》‘’“”\\s]+\"\n",
    "re_obj = re.compile(pattern)\n",
    "def clear(text):\n",
    "    return re_obj.sub(\"\",text)\n",
    "commenthigh11= commenthigh10.apply(clear)\n",
    "\n",
    "# 生成分词\n",
    "commenthigh12 = commenthigh11.apply(lambda x : list(jieba.cut(x)))\n",
    "\n",
    "#停用词处理\n",
    "\n",
    "def get_stopword():\n",
    "    s = set()\n",
    "    with open(r\"呆萌的停用词表.txt\",encoding = 'UTF-8') as f:\n",
    "        for line in f:\n",
    "            s.add(line.strip())\n",
    "    return s\n",
    "\n",
    "def remove_stopword(words):\n",
    "    return [word for word in words if word not in stopword]\n",
    "\n",
    "stopword = get_stopword()\n",
    "commenthigh1 = commenthigh12.apply(remove_stopword)\n",
    "\n",
    "#词频统计\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "li_2d = commenthigh1.tolist()\n",
    "#将二维列表转换为一维\n",
    "li_1d = list(chain.from_iterable(li_2d))\n",
    "print(f'总词汇量：{len(li_1d)}')\n",
    "c = Counter(li_1d)\n",
    "print(f'不重复词汇量：{len(c)}')\n",
    "common = c.most_common(100)\n",
    "print(common)\n",
    "\n",
    "#生成词云图\n",
    "wordhigh1 = WordCloud(init_opts=opts.InitOpts(width='1350px', height='750px', theme=ThemeType.MACARONS))\n",
    "wordhigh1.add('common', data_pair=common,\n",
    "          word_size_range=[15, 108], textstyle_opts=opts.TextStyleOpts(font_family='cursive'),\n",
    "          shape=SymbolType.DIAMOND)\n",
    "wordhigh1.set_global_opts(title_opts=opts.TitleOpts('word2018'),\n",
    "                         toolbox_opts=opts.ToolboxOpts(is_show=True, orient='vertical'),\n",
    "                         tooltip_opts=opts.TooltipOpts(is_show=True, background_color='red', border_color='yellow'))\n",
    "wordhigh1.render(\"wordhigh1.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "044bc6ce-8741-4c2a-8d58-23e0c2a986fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总词汇量：5324\n",
      "不重复词汇量：1603\n",
      "[('加油', 230), ('武汉', 186), ('宝岛', 95), ('十万', 82), ('播放', 73), ('B', 61), ('吹', 56), ('刷', 55), ('弹幕', 53), ('万', 52), ('C', 52), ('考古', 49), ('满地', 43), ('鬼畜', 43), ('中国', 41), ('call', 39), ('春风', 38), ('10w', 35), ('改革', 35), ('冲冲', 33), ('D', 32), ('助攻', 28), ('笑', 26), ('之宝', 26), ('时代', 24), ('哭', 24), ('号', 24), ('争气', 22), ('影流', 21), ('打卡', 21), ('吃', 19), ('两周年', 18), ('病毒', 18), ('镇站', 17), ('大哭', 16), ('助力', 16), ('俩', 16), ('念诗', 15), ('请', 15), ('增加', 15), ('超', 15), ('失败', 15), ('打针', 15), ('吃药', 15), ('一遍', 14), ('之王', 14), ('滑稽', 14), ('两年', 14), ('超过', 14), ('钉', 14), ('瓜', 14), ('粮食', 14), ('大丰收', 14), ('洪水', 14), ('赶跑', 14), ('百姓', 14), ('安居乐业', 14), ('党的领导', 14), ('话疗', 14), ('关闭', 14), ('离地', 14), ('之主', 13), ('前来', 13), ('知识', 13), ('区', 13), ('火辣辣', 13), ('牛', 12), ('真的', 12), ('鸭', 12), ('换', 12), ('赵本山', 12), ('奥力', 12), ('万增', 12), ('记得', 12), ('领导', 12), ('周年', 12), ('增比', 12), ('主', 11), ('春晚', 11), ('流之主', 11), ('世界', 11), ('国外', 11), ('完', 10), ('粉丝', 10), ('理解', 10), ('10W', 10), ('亿', 10), ('日影', 10), ('万新', 10), ('方式', 10), ('第一场', 10), ('雪', 10), ('稍晚', 10), ('成天', 10), ('勾心斗角', 10), ('这是', 9), ('蝙蝠', 9), ('时间', 9), ('刷屏', 9), ('听', 9)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\12297\\\\python学习\\\\python数据分析\\\\wordhigh2.html'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commenthigh20=datahigh2[\"评论\"]\n",
    "\n",
    "#清除特殊符号\n",
    "pattern = r\"[!\\\"#$%&'()*+,-./:;<=>?@[\\\\\\]^_^{|}~—！，。？、￥…（）：【】《》‘’“”\\s]+\"\n",
    "re_obj = re.compile(pattern)\n",
    "def clear(text):\n",
    "    return re_obj.sub(\"\",text)\n",
    "commenthigh21= commenthigh20.apply(clear)\n",
    "\n",
    "# 生成分词\n",
    "commenthigh22 = commenthigh21.apply(lambda x : list(jieba.cut(x)))\n",
    "\n",
    "#停用词处理\n",
    "\n",
    "def get_stopword():\n",
    "    s = set()\n",
    "    with open(r\"呆萌的停用词表.txt\",encoding = 'UTF-8') as f:\n",
    "        for line in f:\n",
    "            s.add(line.strip())\n",
    "    return s\n",
    "\n",
    "def remove_stopword(words):\n",
    "    return [word for word in words if word not in stopword]\n",
    "\n",
    "stopword = get_stopword()\n",
    "commenthigh2 = commenthigh22.apply(remove_stopword)\n",
    "\n",
    "#词频统计\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "li_2d = commenthigh2.tolist()\n",
    "#将二维列表转换为一维\n",
    "li_1d = list(chain.from_iterable(li_2d))\n",
    "print(f'总词汇量：{len(li_1d)}')\n",
    "c = Counter(li_1d)\n",
    "print(f'不重复词汇量：{len(c)}')\n",
    "common = c.most_common(100)\n",
    "print(common)\n",
    "\n",
    "#生成词云图\n",
    "wordhigh2 = WordCloud(init_opts=opts.InitOpts(width='1350px', height='750px', theme=ThemeType.MACARONS))\n",
    "wordhigh2.add('common', data_pair=common,\n",
    "          word_size_range=[15, 108], textstyle_opts=opts.TextStyleOpts(font_family='cursive'),\n",
    "          shape=SymbolType.DIAMOND)\n",
    "wordhigh2.set_global_opts(title_opts=opts.TitleOpts('word2018'),\n",
    "                         toolbox_opts=opts.ToolboxOpts(is_show=True, orient='vertical'),\n",
    "                         tooltip_opts=opts.TooltipOpts(is_show=True, background_color='red', border_color='yellow'))\n",
    "wordhigh2.render(\"wordhigh2.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5179a3d-3feb-4da6-a4a3-f2866b5cb2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总词汇量：6661\n",
      "不重复词汇量：2123\n",
      "[('新年快乐', 300), ('ω', 137), ('脱单', 119), ('播放', 107), ('考古', 98), ('妙', 88), ('福到', 82), ('️', 81), ('打卡', 80), ('三年', 78), ('春晚', 61), ('一亿', 58), ('万', 57), ('小品', 50), ('亿遍', 47), ('弹幕', 46), ('微笑', 45), ('助攻', 44), ('吹', 44), ('赵本山', 44), ('call', 42), ('过年', 42), ('━', 40), ('再来', 39), ('鬼畜', 37), ('亿', 37), ('本山', 37), ('笑', 36), ('经典', 36), ('一遍', 33), ('牛', 32), ('哭', 31), ('春风', 29), ('大叔', 29), ('增加', 28), ('缓存', 28), ('知识', 27), ('时间', 27), ('世界', 26), ('重温', 26), ('好家伙', 26), ('滑稽', 25), ('之宝', 24), ('前来', 24), ('上头', 23), ('回来', 23), ('星星', 22), ('镇站', 22), ('满地', 21), ('刷', 21), ('记得', 21), ('OK', 21), ('眼', 20), ('真的', 20), ('喜极而泣', 20), ('回顾', 20), ('怀念', 20), ('震动', 20), ('改革', 19), ('快乐', 19), ('春节', 18), ('除夕', 18), ('永远', 17), ('眼睛', 16), ('听', 16), ('预言家', 16), ('°', 16), ('dogedoge', 15), ('手机', 15), ('爆', 15), ('风景', 15), ('大哭', 15), ('嗑瓜子', 15), ('完', 14), ('辣', 14), ('有人', 14), ('b', 13), ('为啥', 13), ('老师', 13), ('纵观', 13), ('两年', 12), ('喜欢', 12), ('DNA', 12), ('时代', 12), ('风云', 12), ('7000', 12), ('大爷', 12), ('牛年', 12), ('感觉', 11), ('B', 11), ('念诗', 11), ('之王', 11), ('大笑', 11), ('祝', 11), ('号', 10), ('明天', 10), ('过得', 10), ('狗子', 10), ('独好', 10), ('变', 10)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\12297\\\\python学习\\\\python数据分析\\\\wordhigh3.html'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commenthigh30=datahigh3[\"评论\"]\n",
    "\n",
    "#清除特殊符号\n",
    "pattern = r\"[!\\\"#$%&'()*+,-./:;<=>?@[\\\\\\]^_^{|}~—！，。？、￥…（）：【】《》‘’“”\\s]+\"\n",
    "re_obj = re.compile(pattern)\n",
    "def clear(text):\n",
    "    return re_obj.sub(\"\",text)\n",
    "commenthigh31= commenthigh30.apply(clear)\n",
    "\n",
    "# 生成分词\n",
    "commenthigh32 = commenthigh31.apply(lambda x : list(jieba.cut(x)))\n",
    "\n",
    "#停用词处理\n",
    "\n",
    "def get_stopword():\n",
    "    s = set()\n",
    "    with open(r\"呆萌的停用词表.txt\",encoding = 'UTF-8') as f:\n",
    "        for line in f:\n",
    "            s.add(line.strip())\n",
    "    return s\n",
    "\n",
    "def remove_stopword(words):\n",
    "    return [word for word in words if word not in stopword]\n",
    "\n",
    "stopword = get_stopword()\n",
    "commenthigh3 = commenthigh32.apply(remove_stopword)\n",
    "\n",
    "#词频统计\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "li_2d = commenthigh3.tolist()\n",
    "#将二维列表转换为一维\n",
    "li_1d = list(chain.from_iterable(li_2d))\n",
    "print(f'总词汇量：{len(li_1d)}')\n",
    "c = Counter(li_1d)\n",
    "print(f'不重复词汇量：{len(c)}')\n",
    "common = c.most_common(100)\n",
    "print(common)\n",
    "\n",
    "#生成词云图\n",
    "wordhigh3 = WordCloud(init_opts=opts.InitOpts(width='1350px', height='750px', theme=ThemeType.MACARONS))\n",
    "wordhigh3.add('common', data_pair=common,\n",
    "          word_size_range=[15, 108], textstyle_opts=opts.TextStyleOpts(font_family='cursive'),\n",
    "          shape=SymbolType.DIAMOND)\n",
    "wordhigh3.set_global_opts(title_opts=opts.TitleOpts('word2018'),\n",
    "                         toolbox_opts=opts.ToolboxOpts(is_show=True, orient='vertical'),\n",
    "                         tooltip_opts=opts.TooltipOpts(is_show=True, background_color='red', border_color='yellow'))\n",
    "wordhigh3.render(\"wordhigh3.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "163a3b05-6925-4fb2-8326-f1a3b9ea7215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总词汇量：2382\n",
      "不重复词汇量：885\n",
      "[('一亿', 94), ('加油', 77), ('亿遍', 68), ('再来', 66), ('助攻', 65), ('河南', 56), ('豫', 47), ('吹', 45), ('亿', 40), ('考古', 33), ('播放', 29), ('爆热词', 29), ('打卡', 28), ('笑', 27), ('哭', 24), ('脱单', 24), ('妙', 24), ('弹幕', 22), ('call', 18), ('鬼畜', 17), ('周年', 14), ('之宝', 13), ('知识', 12), ('增加', 12), ('万', 11), ('真的', 11), ('爆', 11), ('刷', 11), ('B', 10), ('镇站', 10), ('影流', 9), ('一遍', 9), ('藏狐', 9), ('三年', 9), ('时代', 8), ('之主', 8), ('感觉', 8), ('第二个', 8), ('支持', 8), ('春风', 8), ('宝岛', 8), ('发现', 8), ('经典', 7), ('先', 7), ('有人', 7), ('时间', 7), ('这么久', 7), ('冲冲', 7), ('前来', 7), ('OK', 7), ('好活', 6), ('记得', 6), ('回来', 6), ('你币', 6), ('争气', 6), ('助力', 6), ('DNA', 6), ('冲热词', 6), ('辣', 6), ('隔壁', 6), ('喜极而泣', 6), ('重温', 5), ('吃', 5), ('手机', 5), ('作品', 5), ('牛', 5), ('上头', 5), ('改革', 5), ('满地', 5), ('洪水', 5), ('饮茶', 5), ('区', 5), ('来古', 5), ('▔', 5), ('小品', 4), ('提前', 4), ('爷', 4), ('有意思', 4), ('喜欢', 4), ('玩', 4), ('开心', 4), ('当年', 4), ('老师', 4), ('好多', 4), ('天才', 4), ('震动', 4), ('请', 4), ('永远', 4), ('东强', 4), ('爷青回', 4), ('起飞', 4), ('这才', 4), ('叕', 4), ('赶跑', 4), ('滑稽', 4), ('一个亿', 4), ('八千万', 4), ('大哭', 4), ('啥时候', 4), ('眼睛', 4)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\12297\\\\python学习\\\\python数据分析\\\\wordhigh4.html'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commenthigh40=datahigh4[\"评论\"]\n",
    "\n",
    "#清除特殊符号\n",
    "pattern = r\"[!\\\"#$%&'()*+,-./:;<=>?@[\\\\\\]^_^{|}~—！，。？、￥…（）：【】《》‘’“”\\s]+\"\n",
    "re_obj = re.compile(pattern)\n",
    "def clear(text):\n",
    "    return re_obj.sub(\"\",text)\n",
    "commenthigh41= commenthigh40.apply(clear)\n",
    "\n",
    "# 生成分词\n",
    "commenthigh42 = commenthigh41.apply(lambda x : list(jieba.cut(x)))\n",
    "\n",
    "#停用词处理\n",
    "\n",
    "def get_stopword():\n",
    "    s = set()\n",
    "    with open(r\"呆萌的停用词表.txt\",encoding = 'UTF-8') as f:\n",
    "        for line in f:\n",
    "            s.add(line.strip())\n",
    "    return s\n",
    "\n",
    "def remove_stopword(words):\n",
    "    return [word for word in words if word not in stopword]\n",
    "\n",
    "stopword = get_stopword()\n",
    "commenthigh4 = commenthigh42.apply(remove_stopword)\n",
    "\n",
    "#词频统计\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "li_2d = commenthigh4.tolist()\n",
    "#将二维列表转换为一维\n",
    "li_1d = list(chain.from_iterable(li_2d))\n",
    "print(f'总词汇量：{len(li_1d)}')\n",
    "c = Counter(li_1d)\n",
    "print(f'不重复词汇量：{len(c)}')\n",
    "common = c.most_common(100)\n",
    "print(common)\n",
    "\n",
    "#生成词云图\n",
    "wordhigh4 = WordCloud(init_opts=opts.InitOpts(width='1350px', height='750px', theme=ThemeType.MACARONS))\n",
    "wordhigh4.add('common', data_pair=common,\n",
    "          word_size_range=[15, 108], textstyle_opts=opts.TextStyleOpts(font_family='cursive'),\n",
    "          shape=SymbolType.DIAMOND)\n",
    "wordhigh4.set_global_opts(title_opts=opts.TitleOpts('word2018'),\n",
    "                         toolbox_opts=opts.ToolboxOpts(is_show=True, orient='vertical'),\n",
    "                         tooltip_opts=opts.TooltipOpts(is_show=True, background_color='red', border_color='yellow'))\n",
    "wordhigh4.render(\"wordhigh4.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75daaf17-5321-4c3a-bca8-10533f0c8221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总词汇量：6213\n",
      "不重复词汇量：1824\n",
      "[('新年快乐', 222), ('考古', 149), ('一遍', 119), ('播放', 111), ('春晚', 104), ('打卡', 94), ('虎年', 73), ('一亿', 65), ('万', 65), ('四年', 62), ('亿', 58), ('过年', 57), ('经典', 56), ('小品', 56), ('冰墩', 51), ('墩', 49), ('本山', 47), ('爱', 45), ('回来', 41), ('笑', 41), ('call', 40), ('辣', 39), ('助攻', 38), ('鬼畜', 38), ('脱单', 37), ('重温', 36), ('大哭', 34), ('助力', 31), ('微笑', 31), ('赵本山', 31), ('大叔', 31), ('怀念', 30), ('妙', 29), ('知识', 29), ('哭', 29), ('脸红', 28), ('我滴', 28), ('红红火火', 28), ('增加', 27), ('前来', 27), ('吹', 27), ('真的', 25), ('星星', 24), ('眼', 23), ('tv', 22), ('春节', 22), ('好家伙', 21), ('回顾', 21), ('时间', 21), ('OK', 21), ('春风', 21), ('完', 21), ('眼睛', 20), ('有人', 20), ('改革', 20), ('手机', 19), ('记得', 19), ('感觉', 18), ('想念', 18), ('弹幕', 18), ('满地', 18), ('震动', 17), ('听', 17), ('吃', 17), ('之宝', 17), ('时代', 17), ('88888', 17), ('老师', 16), ('刷', 16), ('豹富', 16), ('恭喜发财', 16), ('观看', 16), ('为啥', 15), ('看一遍', 15), ('亿遍', 15), ('狗子', 15), ('一年', 14), ('再来', 14), ('大吉大利', 14), ('每日', 13), ('镇站', 13), ('快乐', 13), ('滑稽', 13), ('九千万', 12), ('好看', 12), ('真快', 12), ('报道', 12), ('雪容融', 12), ('身体健康', 12), ('流传', 12), ('永远', 12), ('点', 12), ('大年初一', 12), ('除夕', 11), ('嗑瓜子', 11), ('祝', 11), ('8848', 11), ('喜欢', 11), ('牛', 11), ('88888w', 11)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\12297\\\\python学习\\\\python数据分析\\\\wordhigh5.html'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commenthigh50=datahigh5[\"评论\"]\n",
    "\n",
    "#清除特殊符号\n",
    "pattern = r\"[!\\\"#$%&'()*+,-./:;<=>?@[\\\\\\]^_^{|}~—！，。？、￥…（）：【】《》‘’“”\\s]+\"\n",
    "re_obj = re.compile(pattern)\n",
    "def clear(text):\n",
    "    return re_obj.sub(\"\",text)\n",
    "commenthigh51= commenthigh50.apply(clear)\n",
    "\n",
    "# 生成分词\n",
    "commenthigh52 = commenthigh51.apply(lambda x : list(jieba.cut(x)))\n",
    "\n",
    "#停用词处理\n",
    "\n",
    "def get_stopword():\n",
    "    s = set()\n",
    "    with open(r\"呆萌的停用词表.txt\",encoding = 'UTF-8') as f:\n",
    "        for line in f:\n",
    "            s.add(line.strip())\n",
    "    return s\n",
    "\n",
    "def remove_stopword(words):\n",
    "    return [word for word in words if word not in stopword]\n",
    "\n",
    "stopword = get_stopword()\n",
    "commenthigh5 = commenthigh52.apply(remove_stopword)\n",
    "\n",
    "#词频统计\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "li_2d = commenthigh5.tolist()\n",
    "#将二维列表转换为一维\n",
    "li_1d = list(chain.from_iterable(li_2d))\n",
    "print(f'总词汇量：{len(li_1d)}')\n",
    "c = Counter(li_1d)\n",
    "print(f'不重复词汇量：{len(c)}')\n",
    "common = c.most_common(100)\n",
    "print(common)\n",
    "\n",
    "#生成词云图\n",
    "wordhigh5 = WordCloud(init_opts=opts.InitOpts(width='1350px', height='750px', theme=ThemeType.MACARONS))\n",
    "wordhigh5.add('common', data_pair=common,\n",
    "          word_size_range=[15, 108], textstyle_opts=opts.TextStyleOpts(font_family='cursive'),\n",
    "          shape=SymbolType.DIAMOND)\n",
    "wordhigh5.set_global_opts(title_opts=opts.TitleOpts('word2018'),\n",
    "                         toolbox_opts=opts.ToolboxOpts(is_show=True, orient='vertical'),\n",
    "                         tooltip_opts=opts.TooltipOpts(is_show=True, background_color='red', border_color='yellow'))\n",
    "wordhigh5.render(\"wordhigh5.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fead6d99-2b30-4d2a-aad2-9491a24d11ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
